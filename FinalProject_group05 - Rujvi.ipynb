{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project\n",
    "\n",
    "## Permissions\n",
    "\n",
    "Place an X in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that PIDs will be scraped from the public submission, but student names will be included.)\n",
    "\n",
    "- [X] YES - make available\n",
    "- [ ] NO - keep private\n",
    "\n",
    "## Overview\n",
    "\n",
    "## Names\n",
    "\n",
    "- Gadi Rosen\n",
    "- Rujvi Mehendre\n",
    "- Henry Lozada\n",
    "- Joshua Paz\n",
    "\n",
    "## Group Members IDs\n",
    "\n",
    "- A16105613\n",
    "- A14553468\n",
    "- A15127559\n",
    "- A13300845\n",
    "\n",
    "## Research Question\n",
    "\n",
    "\"_How has the outbreak of COVID-19 affected food security in communities in the greater San Diego area?_\"\n",
    "\n",
    "## Background & Prior Work\n",
    "\n",
    "#### Why is this project of interest to your group?\n",
    " The pandemic has claimed many lives, but its impact on the US goes beyond that. People of limited financial means have been disproportionately affected by the stay-at-home orders issued. In light of this, we believe it’s important to consider how the pandemic, and the stay-at-home orders issued, affect people’s livelihoods and access to food.\n",
    "\n",
    "#### What background information led to your hypothesis?\n",
    " Certain communities in the greater San Diego area had suffered from food insecurity prior to the advent of this pandemic1. According to an article on Fortune magazine2, since the beginning of the pandemic, unemployment has skyrocketed from 4% to nearly 18%. Another article by Fortune3, published 04/09/2020, states that “The total weekly claims fell close to 1.4 million from last week's 6.6 million initial unemployment claims.” Furthermore, according to an article published on yahoo! finance4, “Economists had been expecting the report to show the ranks of jobless Americans increasing by 5.5 million.” Meanwhile, information made available by the USDA5 indicates that food production has been decreasing as a result of the pandemic. Consequently, food banks are reporting an unprecedented increase in demand6, and the possibility of the US facing a food crisis is real.\n",
    "\n",
    "#### Why is this important?\n",
    " We believe that this pandemic’s impact on the US goes beyond the lives it has claimed. The advent of the pandemic has resulted in stay-at-home orders which have increased the number of jobless Americans, limiting their financial resources and thus their ability to secure basic necessities, such as food. An analysis of the pandemic’s effect on the public’s access to food could result in a better understanding of the area’s food supply chain, which could be used by decision-makers and other relevant stakeholders to alleviate current shortages, and perhaps to prevent other shortages from occurring in the future.\n",
    "\n",
    "#### What has already been done on this topic? What is already known?\n",
    " COVID-19 is a respiratory virus that is highly contagious and has infected well over 210 countries around the world, resulting in an on-going global pandemic. In order to curtail the spread of the disease, many governments have issued strict stay-at-home directives. These directives have resulted in the closure of businesses and increased unemployment.\n",
    "\n",
    " There have been studies and visualizations done in many countries worldwide highlighting spots where food insecurity is prevalent. These studies demonstrate that COVID-19 has only aggravated food insecurity, especially in countries where food insecurity was already prevalent.\n",
    "\n",
    "#### References:\n",
    "1. Food deserts and access to fresh food in low-income San Diego / by Emily Theresa Puhl\n",
    "2. 22 million have lost their jobs over the past month—real unemployment rate likely nearing 18%\n",
    "3. Real unemployment in the United States has likely hit 14.7%, the highest level since 1940\n",
    "4. Jobless claims: Another 5.245 million Americans file for unemployment benefits\n",
    "5. USDA - Quick Stats\n",
    "6. A perfect storm: US facing hunger crisis as demand for food banks soars\n",
    "7. COVID-19\n",
    "#### Additional sources:\n",
    "1. San Diego Hunger Coalition\n",
    "2. UCSD Community Health\n",
    "3. Foods Typically Purchased by Supplemental Nutrition Assistance Program (SNAP) Households\n",
    "4. Food Security Information Network\n",
    "5. Feeding San Diego\n",
    "6. Neighborhood distribution Program\n",
    "7. Food assistance during COVID-19 Pandemic\n",
    "8. Greater Pittsburgh Community Foodbank - Our response to COVID-19\n",
    "9. USDA - Coronavirus Disease\n",
    "10. Nutritional Goals for Age-Sex Groups Based on Dietary Reference Intakes and Dietary Guidelines Recommendations\n",
    "\n",
    "### Hypothesis:\n",
    "The outbreak of COVID-19 has negatively impacted individuals’ access to food, disproportionately affecting the financially insecure and communities of color. These groups were already limited in their ability to provide for themselves and their families, and the pandemic has only made it more difficult for them to do so.\n",
    "\n",
    "### Data:\n",
    "1. San Diego Foodbank - Lbs of food distributed\n",
    "2. SANDAG/SanGIS regional GIS data\n",
    "2. SANDAG 2018 population estimates by Zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import fiona\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (17, 5)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "\n",
    "import shapely.geometry as shp\n",
    "\n",
    "import sklearn.neighbors as skn\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "#improve resolution\n",
    "#comment this line if erroring on your machine/screen\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"Census_Data/Census_ZIP.shp\"\n",
    "tempmap = gpd.read_file(filepath)\n",
    "pop = pd.read_excel(\"Household Population ZIP.xlsx\")\n",
    "sdmap= pd.merge(tempmap, pop, on='ZIP', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Population by Zip code\n",
    "fig, ax = plt.subplots(1, 1, figsize=(17, 7))\n",
    "divider = make_axes_locatable(ax)\n",
    "sdmap.plot(column='POPULATION', ax=ax, cmap='GnBu', legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = gpd.read_file('ADDRESS_APN.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses.head(5)\n",
    "#addresses[addresses['ADDRFRAC'] != \"None\"]\n",
    "#Check to see if 14925 Great Southern Overland Stage in addresses\n",
    "#Is \"Glen\", \"Broadway\" and ADDRNAME?\n",
    "#How to handle highways? Ex: 4141 Pacific Highway\n",
    "#addresses['ADDRSFX'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in all foodbank data\n",
    "#2019\n",
    "Jan2019 = pd.read_excel(\"San_Diego_Foodbank_Data/Jan 2019.xlsx\")\n",
    "Feb2019 = pd.read_excel(\"San_Diego_Foodbank_Data/Feb 2019.xlsx\")\n",
    "Mar2019 = pd.read_excel(\"San_Diego_Foodbank_Data/Mar 2019.xlsx\")\n",
    "Apr2019 = pd.read_excel(\"San_Diego_Foodbank_Data/Apr 2019.xlsx\")\n",
    "#2020\n",
    "Jan2020 = pd.read_excel(\"San_Diego_Foodbank_Data/Jan 2020.xlsx\")\n",
    "Feb2020 = pd.read_excel(\"San_Diego_Foodbank_Data/Feb 2020.xlsx\")\n",
    "Mar2020 = pd.read_excel(\"San_Diego_Foodbank_Data/Mar 2020.xlsx\")\n",
    "Apr2020 = pd.read_excel(\"San_Diego_Foodbank_Data/Apr 2020.xlsx\")\n",
    "\n",
    "#Note: Number of foodbanks sampled varies from year to year and month to month.\n",
    "#----------------------------------------------------------------------------------\n",
    "    # Jan 2019: 452\n",
    "    # Feb 2019: 387\n",
    "    # Mar 2019: 431\n",
    "    # Apr 2019: 418\n",
    "    #--------------\n",
    "    # Jan 2020: 486\n",
    "    # Feb 2020: 331\n",
    "    # Mar 2020: 481\n",
    "    # Apr 2020: 454\n",
    "#----------------------------------------------------------------------------------\n",
    "# Suggestion: Consider only foodbanks that consistently appear throughout all dfs.\n",
    "# Solution: Merge all of the dfs by inner?\n",
    "col = pd.merge(Jan2019, Feb2019, on='STREET ADDRESS', how='inner')\n",
    "col = pd.merge(col, Mar2019, on='STREET ADDRESS', how='inner')\n",
    "col = pd.merge(col, Apr2019, on='STREET ADDRESS', how='inner')\n",
    "col = pd.merge(col, Jan2020, on='STREET ADDRESS', how='inner')\n",
    "col = pd.merge(col, Feb2020, on='STREET ADDRESS', how='inner')\n",
    "col = pd.merge(col, Mar2020, on='STREET ADDRESS', how='inner')\n",
    "col = pd.merge(col, Apr2020, on='STREET ADDRESS', how='inner')\n",
    "col.drop_duplicates(subset=\"STREET ADDRESS\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If done correctly, there are only 193 foodbanks that appear in all records. We will work exclusively with these.\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function to split STREET ADDRESS into:\n",
    "#     1. ADDRNMBR\n",
    "#     2. ADDRFRAC\n",
    "#     3. ADDRNAME\n",
    "#     4. ADDRUNIT\n",
    "\"\"\" \n",
    "1. Avenue X\n",
    "2. Drive X\n",
    "3. Street X\n",
    "4. Ave X\n",
    "5. Lane X\n",
    "6. St. X\n",
    "7. Way X\n",
    "8. Dr. X\n",
    "9. Ave. X\n",
    "10. St X\n",
    "11. Road X\n",
    "12. Dr X\n",
    "13. Blvd X\n",
    "14. Rd X\n",
    "15. Boulevard X\n",
    "16. Glen?\n",
    "17. Trail\n",
    "18. Circle\n",
    "19. Terrace\n",
    "20. Parkway\n",
    "21. Place\n",
    "22. Park\n",
    "23. Court\n",
    "24. Route\"\"\"\n",
    "\n",
    "\n",
    "def standardize_address(string):\n",
    "    try:\n",
    "        string = string.upper()\n",
    "        string = string.split(\" \", 1)\n",
    "        if \"-\" in string[0]:\n",
    "            string[0].split(\"-\", 1)\n",
    "            addrnumber = string[0].split(\"-\")[0]\n",
    "            addrunit = string[0].split(\"-\")[1]\n",
    "        else:\n",
    "            addrnumber = float(string[0])\n",
    "        addrsfx = \"\"\n",
    "        addrsuite = \"\"\n",
    "        addrname = \"\"\n",
    "        print(string)\n",
    "        string = string[1]\n",
    "        print(\"after strip\" + string)\n",
    "        if \",\" in string:\n",
    "            string = string.rsplit(\",\", 1)\n",
    "            print(string)\n",
    "            addrsuite = string[1].strip()\n",
    "            string = string[0]\n",
    "        AveSuffixes = ['Avenue', 'Ave', 'Ave.']\n",
    "        DriveSuffixes = ['Drive', 'Dr', 'Dr.']\n",
    "        StreetSuffixes = ['Street', 'St.', 'St']\n",
    "        RoadSuffixes = ['Road', 'Rd']\n",
    "        BoulevardSuffixes = ['Boulevard', 'Blvd']\n",
    "        print(string)\n",
    "        for e in AveSuffixes:\n",
    "            if e.upper() in string:\n",
    "                addrsfx = 'AVE'\n",
    "                string = string.split(e.upper(), 1)\n",
    "\n",
    "        for e in RoadSuffixes:\n",
    "            if e.upper() in string and \"BROADWAY\" not in string:\n",
    "                addrsfx = 'RD'\n",
    "                string = string.split(e.upper(), 1)\n",
    "\n",
    "        for e in StreetSuffixes:\n",
    "            if e.upper() in string:\n",
    "                addrsfx = 'ST'\n",
    "                string = string.split(e.upper(), 1)\n",
    "\n",
    "        for e in DriveSuffixes:\n",
    "            if e.upper() in string:\n",
    "                addrsfx = 'DR'\n",
    "                string = string.split(e.upper(), 1)\n",
    "\n",
    "        for e in BoulevardSuffixes:\n",
    "            if e.upper() in string:\n",
    "                addrsfx = 'BLVD'\n",
    "                string = string.split(e.upper(), 1)\n",
    "        print(string)\n",
    "        if \"LANE\" in string:\n",
    "            addrsfx = 'LN'\n",
    "            string = string.split(\"LANE\", 1)\n",
    "\n",
    "        elif \" WAY\" in string and \"BROADWAY\" not in string:\n",
    "            addrsfx = 'WAY'\n",
    "            string = string.split(\"WAY\", 1)\n",
    "            print(\"inside way\" + string)\n",
    "        elif \"BROADWAY\" in string:\n",
    "            addrname = \"BROADWAY\"\n",
    "            print(\"inside broadway\" + string)\n",
    "        elif \"GLEN\" in string:\n",
    "            addrsfx = 'GLEN'\n",
    "            string = string.split(\"GLEN\", 1)\n",
    "\n",
    "        elif \"PARKWAY\" in string:\n",
    "            addrsfx = \"PKWY\"\n",
    "            string = string.split(\"PARKWAY\", 1)\n",
    "\n",
    "        elif \"TRAIL\" in string:\n",
    "            addrsfx = \"TRL\"\n",
    "            string = string.split(\"TRAIL\", 1)\n",
    "\n",
    "        elif \"CIRCLE\" in string:\n",
    "            addrsfx = \"CIR\"\n",
    "            string = string.split(\"CIRCLE\", 1)\n",
    "\n",
    "        elif \"TERRACE\" in string:\n",
    "            addrsfx = \"TER\"\n",
    "            string = string.split(\"TERRACE\", 1)\n",
    "\n",
    "        elif \"PLACE\" in string:\n",
    "            addrsfx = \"PL\"\n",
    "            string = string.split(\"PLACE\", 1)\n",
    "\n",
    "        elif \"PARK\" in string:\n",
    "            addrsfx = \"PARK\"\n",
    "            string = string.split(\"PARK\", 1)\n",
    "\n",
    "        elif \"COURT\" in string:\n",
    "            addrsfx = \"CT\"\n",
    "            string = string.split(\"COURT\", 1)\n",
    "\n",
    "        elif \"ROUTE\" in string:\n",
    "            addrsfx = \"RTE\" # Try RT if this doesn't work\n",
    "            string = string.split(\"ROUTE\", 1)\n",
    "        print(string)\n",
    "        if(addrsfx!=\"\"):\n",
    "            addrname = string[0].strip()\n",
    "\n",
    "        return addrnumber, addrname, addrsfx, addrsuite\n",
    "    \n",
    "    except:\n",
    "        print(\"no good\")\n",
    "\n",
    "\n",
    "\n",
    "    # check rows, cols, check weird cases\n",
    "    # unique rows and columns with .unique() function\n",
    "    # printing every column in terms of a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list of lists \n",
    "  \n",
    "# Create the pandas DataFrame \n",
    "#data = pd.DataFrame(data, columns = ['number', 'name', 'suffix', 'suite', 'unit'])\n",
    "#temp = col.iloc[0,2]\n",
    "#temp\n",
    "standardize_address('542 Grape Vie Road, ste 200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomefile = pd.read_excel(\"income_sd.xlsx\")\n",
    "incomefile = incomefile.loc[incomefile['YEAR'] == 2018]\n",
    "incomefile = incomefile.reset_index()\n",
    "incomefile.head(10)\n",
    "len(incomefile['ZIP'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomefile['INCOME GROUP'] = incomefile['INCOME GROUP'].astype(str)\n",
    "dataTypeSeries =  incomefile.dtypes\n",
    " \n",
    "print('Data type of each column of Dataframe :')\n",
    "#print(dataTypeSeries)\n",
    "#incomefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "incomefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomefile['INCOME GROUP'].replace({\"Less than $15,000\": 10000}, inplace=True)\n",
    "incomefile['INCOME GROUP'].replace({\"$15,000 to $29,999\": 23000}, inplace=True)\n",
    "incomefile['INCOME GROUP'].replace({\"$30,000 to $44,999\": 37500}, inplace=True)\n",
    "incomefile['INCOME GROUP'].replace({\"$45,000 to $59,999\": 52500}, inplace=True)\n",
    "incomefile['INCOME GROUP'].replace({\"$60,000 to $74,999\": 67500}, inplace=True)\n",
    "incomefile['INCOME GROUP'].replace({\"$75,000 to $99,999\": 87500}, inplace=True)\n",
    "incomefile['INCOME GROUP'].replace({\"$100,000 to $124,999\": 112500}, inplace=True)\n",
    "incomefile['INCOME GROUP'].replace({\"$125,000 to $149,999\": 137500}, inplace=True)\n",
    "incomefile['INCOME GROUP'].replace({\"$150,000 to $199,999\": 175000}, inplace=True)\n",
    "incomefile['INCOME GROUP'].replace({\"$200,000 or more\": 220000}, inplace=True)\n",
    "incomefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped = incomefile.groupby('ZIP')\n",
    "df = incomefile.groupby('ZIP').apply(lambda x: x['INCOME GROUP']*x['HOUSEHOLDS'])\n",
    "#print(incomefile)\n",
    "df2 = incomefile.groupby('ZIP')['HOUSEHOLDS'].sum()\n",
    "#print(df2)\n",
    "df = df.groupby('ZIP').sum()\n",
    "\n",
    "#df = df.groupby('ZIP')\n",
    "#df = df.apply(lambda x: x['INCOME GROUP']/x['HOUSEHOLDS'])\n",
    "\n",
    "#df2 = df.apply(lambda x: x['INCOME GROUP']/x['HOUSEHOLDS'])\n",
    "df.dtypes\n",
    "df = df.reset_index() \n",
    "#print(df)\n",
    "df.columns = ['ZIP', 'TOTAL INCOME']\n",
    "df2.colums = ['ZIP', 'HOUSEHOLDS']\n",
    "newincome = df.merge(df2, on = 'ZIP', how = 'inner')\n",
    "print(newincome)\n",
    "income = newincome.groupby('ZIP')\n",
    "income = income.apply(lambda x: x['TOTAL INCOME']/x['HOUSEHOLDS'])\n",
    "income = income.reset_index()\n",
    "income.columns = ['ZIP', 'IND', 'AVERAGE INCOME']\n",
    "val = income[income['AVERAGE INCOME'] == income['AVERAGE INCOME'].max()]\n",
    "less = income[income['AVERAGE INCOME'] == income['AVERAGE INCOME'].min()]\n",
    "print(val)\n",
    "print(less)\n",
    "income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath1 = \"Census_Data/Census_ZIP.shp\"\n",
    "#tempmap1 = gpd.read_file(filepath1)\n",
    "#pop = pd.read_excel(\"Household Population ZIP.xlsx\")\n",
    "#sdmap1= pd.merge(tempmap1, income, on='ZIP', how='left')\n",
    "duplicateRowsDF = income[income.duplicated()]\n",
    "income.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath1 = \"CENSUS-Data/Census_ZIP.shp\"\n",
    "tempmap1 = gpd.read_file(filepath1)\n",
    "\n",
    "\n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(17, 7))\n",
    "divider1 = make_axes_locatable(ax1)\n",
    "sdmap1= pd.merge(tempmap1, income, on='ZIP', how='left')\n",
    "sdmap1 = sdmap1.dropna()\n",
    "sdmap1.plot(column='AVERAGE INCOME', ax=ax1, cmap='GnBu', legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>POPULATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91901</td>\n",
       "      <td>2010</td>\n",
       "      <td>American Indian</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91901</td>\n",
       "      <td>2010</td>\n",
       "      <td>Asian</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91901</td>\n",
       "      <td>2010</td>\n",
       "      <td>Black</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91901</td>\n",
       "      <td>2010</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91901</td>\n",
       "      <td>2010</td>\n",
       "      <td>Other</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8131</th>\n",
       "      <td>92672</td>\n",
       "      <td>2018</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>92672</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8133</th>\n",
       "      <td>92672</td>\n",
       "      <td>2018</td>\n",
       "      <td>Pacific Islander</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8134</th>\n",
       "      <td>92672</td>\n",
       "      <td>2018</td>\n",
       "      <td>Two or More</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8135</th>\n",
       "      <td>92672</td>\n",
       "      <td>2018</td>\n",
       "      <td>White</td>\n",
       "      <td>2330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8136 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ZIP  YEAR         ETHNICITY  POPULATION\n",
       "0     91901  2010   American Indian         266\n",
       "1     91901  2010             Asian         328\n",
       "2     91901  2010             Black         184\n",
       "3     91901  2010          Hispanic        2690\n",
       "4     91901  2010             Other          10\n",
       "...     ...   ...               ...         ...\n",
       "8131  92672  2018          Hispanic        1307\n",
       "8132  92672  2018             Other          11\n",
       "8133  92672  2018  Pacific Islander          22\n",
       "8134  92672  2018       Two or More         161\n",
       "8135  92672  2018             White        2330\n",
       "\n",
       "[8136 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth = pd.read_excel(\"ethnicity.xlsx\")\n",
    "eth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth['ETHNICITY'].unique()\n",
    "eth = eth[eth['YEAR'] == 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop(df):\n",
    "    props = []\n",
    "    for i in range(len(df)):\n",
    "        zipc = df.iloc[i]['ZIP']\n",
    "        if zipc in pop.index:\n",
    "            props.append(df.iloc[i]['POPULATION']/pop[zipc])\n",
    "        else:\n",
    "            continue\n",
    "    df['PROPORTION'] = props\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-590154efb430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0methTM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ETHNICITY'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Two or More'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0methW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ETHNICITY'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'White'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0methAI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0methA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0methB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-b381b134eecf>\u001b[0m in \u001b[0;36mprop\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mzipc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZIP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mzipc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mprops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'POPULATION'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mzipc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pop' is not defined"
     ]
    }
   ],
   "source": [
    "ethAI = eth[eth['ETHNICITY'] == 'American Indian']\n",
    "ethA = eth[eth['ETHNICITY'] == 'Asian']\n",
    "ethB = eth[eth['ETHNICITY'] == 'Black']\n",
    "ethH = eth[eth['ETHNICITY'] == 'Hispanic']\n",
    "ethO = eth[eth['ETHNICITY'] == 'Other']\n",
    "ethPI = eth[eth['ETHNICITY'] == 'Pacific Islander']\n",
    "ethTM = eth[eth['ETHNICITY'] == 'Two or More']\n",
    "ethW = eth[eth['ETHNICITY'] == 'White']\n",
    "prop(ethAI)\n",
    "prop(ethA)\n",
    "prop(ethB)\n",
    "prop(ethH)\n",
    "prop(ethO)\n",
    "prop(ethPI)\n",
    "prop(ethTM)\n",
    "prop(ethW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
